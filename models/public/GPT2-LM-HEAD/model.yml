# Copyright (c) 2020 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

description: >-
  GPT2-LM-HEAD: Transformer-based language model for text generation. For details
  see the paper <https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf>,
  original repository <https://github.com/huggingface/transformers> and repository
  with converted model <https://github.com/onnx/models/tree/master/text/machine_comprehension/gpt-2>.
task_type: text_prediction
files:
  - name: gpt2-lm-head-10.onnx
    size: 664870493
    sha256: 519650b01bc3dfa0b556fbe6d76ab3938ec6c70310b49ba31ddc3024be3641ad
    source: https://media.githubusercontent.com/media/onnx/models/d43d88886da3bf4aa77ba8c1774137179907fe17/text/machine_comprehension/gpt-2/model/gpt2-lm-head-10.onnx
model_optimizer_args:
  - --input_shape=[1,1,1024]
  - --input=input1
  - --input_model=$dl_dir/gpt2-lm-head-10.onnx
  - --output=MatMul_2533
framework: onnx
license: https://github.com/huggingface/transformers/blob/master/LICENSE
